{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import yelp_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yelp_review = pd.read_pickle('data/yelp_academic_dataset_review.pickle') # read yelp review pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "breaking into sentence...\n",
      "trianing word2vec model...\n"
     ]
    }
   ],
   "source": [
    "review_list = list(yelp_review.text.iloc[10000:11000]) # example of review\n",
    "word2vec_model = yelp_util.create_word2vec_model(review_list, size=100) # create word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "review_words_stream = yelp_util.get_stream_seq(review_list, word2vec_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size:  1294\n",
      "Word vector dimension:  100\n"
     ]
    }
   ],
   "source": [
    "embeddings = yelp_util.get_word_embedding(word2vec_model) # get word vector embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "args = yelp_util.InputParameter()\n",
    "# correct default parameters\n",
    "args.vocab_size = embeddings.shape[0]\n",
    "args.rnn_size = embeddings.shape[1]\n",
    "args.batch_size = 10\n",
    "args.seq_length = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = yelp_util.ReviewModel(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size, seq_length = 10, 25\n",
    "sequence_streamer = yelp_util.SeqStream(review_words_stream, batch_size, seq_length) # where review words stream is the stream of word2vec index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103250\n"
     ]
    }
   ],
   "source": [
    "print len(sequence_streamer.tensor) # class of reviews stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/20650 (epoch 0), train_loss = 7.710, time/batch = 0.591\n",
      "500/20650 (epoch 1), train_loss = 5.608, time/batch = 0.126\n",
      "1000/20650 (epoch 2), train_loss = 5.425, time/batch = 0.147\n",
      "1500/20650 (epoch 3), train_loss = 5.172, time/batch = 0.138\n",
      "2000/20650 (epoch 4), train_loss = 5.175, time/batch = 0.125\n",
      "2500/20650 (epoch 6), train_loss = 4.999, time/batch = 0.146\n",
      "3000/20650 (epoch 7), train_loss = 4.829, time/batch = 0.126\n",
      "3500/20650 (epoch 8), train_loss = 4.774, time/batch = 0.133\n",
      "4000/20650 (epoch 9), train_loss = 5.017, time/batch = 0.144"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    tf.initialize_all_variables().run()\n",
    "    saver = tf.train.Saver(tf.all_variables())\n",
    "    for e in xrange(args.num_epochs):\n",
    "        sess.run(tf.assign(model.lr, args.learning_rate * (args.decay_rate ** e)))\n",
    "        sequence_streamer.reset_batch_pointer()\n",
    "        state = model.initial_state.eval(session=sess)\n",
    "        for b in xrange(sequence_streamer.num_batches):\n",
    "            start = time.time()\n",
    "            x, y = sequence_streamer.next_batch()\n",
    "            feed = {model.input_data: x, model.targets: y, model.initial_state: state, model.embedding: embeddings}\n",
    "            train_loss, state, _ = sess.run([model.cost, model.final_state, model.train_op], feed)\n",
    "            end = time.time()\n",
    "            if ((e * sequence_streamer.num_batches + b) % 500) == 0:\n",
    "                print \"{}/{} (epoch {}), train_loss = {:.3f}, time/batch = {:.3f}\" \\\n",
    "                    .format(e * sequence_streamer.num_batches + b,\n",
    "                            args.num_epochs * sequence_streamer.num_batches,\n",
    "                            e, train_loss, end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
